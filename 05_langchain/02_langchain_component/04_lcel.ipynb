{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a02017b",
   "metadata": {},
   "source": [
    "# LCEL(LangChain Expression Language)\n",
    "https://reference.langchain.com/python/langchain_core/runnables/\n",
    "\n",
    "https://reference.langchain.com/python/langchain_core/runnables/?h=runnablelambd#langchain_core.runnables.base.RunnableLambda\n",
    "  \n",
    "- LCEL(LangChain Expression Language)은 LangChain에서 체인을 선언적으로 구성할 수 있게 해주는 도메인 특화 언어다.  \n",
    "- `|` 연산자를 사용해 프롬프트, 모델, 파서 등을 파이프라인처럼 연결한다.\n",
    "\n",
    "**주요 특징**\n",
    "\n",
    "- **선언적 문법**: Unix 파이프처럼 `chain = prompt | model | parser` 형태로 직관적이다.  \n",
    "- **모듈성·유연성**: 프롬프트, LLM, 파서, 검색기, 메모리 등 컴포넌트를 자유롭게 조합할 수 있다.  \n",
    "- **동기/비동기 지원**: 단일 코드로 동기식·비동기식 실행을 모두 처리할 수 있다.  \n",
    "- **병렬 처리 최적화**: 병렬 실행 가능한 단계는 자동으로 병렬화해 지연 시간을 줄인다.  \n",
    "- **고급 기능 기본 제공**:  \n",
    "  - 스트리밍 출력으로 응답 속도를 향상시킨다.  \n",
    "  - 실패 시 재시도와 폴백 경로를 설정할 수 있다.  \n",
    "  - 중간 결과에 접근해 디버깅이나 진행 상황 표시가 가능하다.\n",
    "\n",
    "**LCEL의 주요 기능**\n",
    "\n",
    "1. **스트리밍 지원**: 첫 토큰 도달 시간을 단축해 실시간성을 높인다.  \n",
    "2. **비동기 지원**: asyncio 환경 등 다양한 실행 환경을 동일 코드로 지원한다.  \n",
    "3. **병렬 실행 최적화**: 병렬화 가능한 단계는 자동으로 분리해 동시에 실행한다.  \n",
    "4. **재시도·폴백 구성**: 오류 발생 시 지정 횟수만큼 재시도하거나 대체 경로를 실행한다.  \n",
    "5. **중간 결과 접근**: 최종 출력 이전에 각 단계의 출력을 확인할 수 있다.\n",
    "\n",
    "**기본 구성 요소**\n",
    "\n",
    "- **Runnable**: LCEL의 모든 컴포넌트가 상속하는 기본 클래스다.  \n",
    "- **Chain**: 여러 Runnable을 순차적으로 실행한다.  \n",
    "- **RunnableMap**: 여러 Runnable을 병렬로 실행한다.  \n",
    "- **RunnableSequence**: Runnable들의 시퀀스를 정의한다.  \n",
    "- **RunnableLambda**: 파이썬 함수를 래핑해 Runnable로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7b19e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai -Uqqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293000d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv  # .env 파일의 환경변수 로드\n",
    "import os                       # 환경변수 접근용\n",
    "\n",
    "load_dotenv()                   # 현재 위치의 .env를 읽어와 환경변수로 등록\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"openai_key\")  # .env의 openai_key 값을 OPENAI_API_KEY로 등록\n",
    "os.environ[\"LANGSMITH_TRACING\"] = 'true'                # LangSmith 트레이싱 활성화\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = 'https://api.smith.langchain.com'  # LangSmith API 엔드포인트 설정\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = 'skn23-langchain'                   # LangSmith 프로젝트명 설정\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"langsmith_key\")          # .env의 langsmith_key 값을 LANGSMITH_API_KEY로 등록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74b0ef8",
   "metadata": {},
   "source": [
    "## RunnableLambda\n",
    "일반 python 함수를 lcel 체인에서 사용할 수 있게 wrapping 처리하는 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5248bc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda  # 입력을 받아 함수를 실행하는 Runnable\n",
    "\n",
    "runnable = RunnableLambda(lambda x: len(x))          # 입력 x의 길이를 반환하는 Runnable 생성\n",
    "runnable.invoke('플레이데이터 독산 skn-23 화이팅!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e933e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 2, 6, 4]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch : 여러 건의 입력을 일괄처리하는 메소드\n",
    "runnable.batch(['플레이데이터', '독산', 'skn-23', '화이팅!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f5d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32.0, 77.0, 212.0, 14.0, 98.6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 섭씨 입력값을 화씨로 변환하는 runnable 생성\n",
    "def celsius_to_fahrenheit(celsius):\n",
    "    \"\"\"섭씨 온도를 화씨 온도로 변환하는 함수\"\"\"\n",
    "    return celsius * 9 / 5 + 32  # 섭씨 -> 화씨 변환 공식\n",
    "\n",
    "celsius_temps = [0, 25, 100, -10, 37]\n",
    "runnable = RunnableLambda(celsius_to_fahrenheit)  # 함수를 Runnable로 래핑\n",
    "runnable.batch(celsius_temps)  # 여러 입력을 한 번에 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be401e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요? 안녕하세요! 안녕하세요~ 안녕하세요? 안녕하세요! 안녕하세요~ 안녕하세요? 안녕하세요! 안녕하세요~ 안녕하세요? 안녕하세요! 안녕하세요~ 안녕하세요? 안녕하세요! 안녕하세요~"
     ]
    }
   ],
   "source": [
    "# stream으로 제너레이터 출력 스트리밍하기\n",
    "import time  # 출력 딜레이용\n",
    "\n",
    "def gen(x):\n",
    "    \"\"\"입력 문자열을 한 글자(문자)씩 yield하는 제너레이터\"\"\"\n",
    "    for y in x:    # 입력을 순회(문자 단위)\n",
    "        yield y    # 한 글자씩 반환(스트리밍 단위)\n",
    "\n",
    "runnable = RunnableLambda(gen)  # 문자열 제너레이터 함수를 Runnable로 래핑\n",
    "for chunk in runnable.stream(\"안녕하세요? 안녕하세요! 안녕하세요~ 안녕하세요? 안녕하세요! 안녕하세요~ 안녕하세요? 안녕하세요! 안녕하세요~ 안녕하세요? 안녕하세요! 안녕하세요~ 안녕하세요? 안녕하세요! 안녕하세요~\"):\n",
    "    print(chunk, end='', flush=True)  # chunk를 줄바꿈 없이 즉시 출력\n",
    "    time.sleep(0.1)                   # 0.1초 간격으로 천천히 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0966a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object gen at 0x00000242794BB040>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen(x):\n",
    "    \"\"\"iterable을 받아 원소를 하나씩 yield하는 제너레이터\"\"\"\n",
    "    for y in x:    # 입력을 순회(iterable)\n",
    "        yield y    # 원소를 하나씩 순회\n",
    "\n",
    "gen10 = gen(range(10))  # 0~9를 하나씩 꺼내는 제너레이터 생성\n",
    "gen10  # 객체 자체 실행 (실행 전 / 소모 전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in gen10:  # gen10에서 값을 하나씩 꺼내며 순회 (꺼낸 값은 다시 사용못함)\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c004c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen10 = gen(range(10))  # 0~9를 하나씩 꺼내는 제너레이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e11de09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen10)  # 제너레이터에서 다음 값을 1개 반환 (다 꺼내면 StopIteration 발생)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3920b6",
   "metadata": {},
   "source": [
    "## RunnableSequence\n",
    "Runnable객체를 순차연결하는 Runnable 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c588701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'foo': 3}, {'foo': 3}, {'foo': 3}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence  # Runnable들을 순서대로 연결하는 시퀀스\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {'foo': x})  # 입력 x를 {'foo': x} 형태로 변환\n",
    "runnable2 = RunnableLambda(lambda x: [x] * 3)     # 입력 x를 리스트 3번 반복 [x, x, x]\n",
    "\n",
    "chain = RunnableSequence(runnable1, runnable2)\n",
    "# chain = runnable1 | runnable2  # 위와 동일\n",
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdecad85",
   "metadata": {},
   "source": [
    "## RunnableParellel\n",
    "여러 Runnable객체를 인자로 받아, 병렬처리 후 각각의 응답을 하나의 dict 형태로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e026113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r1': {'foo': 3}, 'r2': [3, 3, 3]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel  # 여러 Runnable들을 같은 입력으로 병렬 실행\n",
    "\n",
    "runnable1 = RunnableLambda(lambda x: {'foo': x})  # 입력 x를 {'foo': x} 형태로 변환\n",
    "runnable2 = RunnableLambda(lambda x: [x] * 3)     # 입력 x를 리스트 3번 반복 [x, x, x]\n",
    "\n",
    "chain = RunnableParallel(r1=runnable1, r2=runnable2)  # r1, r2를 병렬로 실행해 결과를 dict로 묶음\n",
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3414848d",
   "metadata": {},
   "source": [
    "사용자가 지정한 주제(topic)에 대해서 삼행시, 농담, 시를 각각 생성하여 하나의 응답을 작성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aed6ce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n행시:\n",
      "아: 아주 더운 날엔  \n",
      "이: 이대로 녹기 전에  \n",
      "스: 스르르 입안에 넣어  \n",
      "크: 크리미한 달콤함을 느끼고  \n",
      "림: 림(임)자, 오늘 하루도 기분 좋게 마무리!\n",
      "\n",
      "농담:\n",
      "아이스크림 먹다가 너무 감동해서 눈물이 났어요.  \n",
      "왜냐면… **내 인생도 얘처럼 빨리 녹거든요.**\n",
      "\n",
      "시:\n",
      "혀끝에 닿는 순간  \n",
      "여름은 잠깐,  \n",
      "세상에서 가장 부드러운 속도로 녹아내린다.\n",
      "\n",
      "유리창 밖의 햇빛이  \n",
      "마치 오래된 약속처럼 반짝이면  \n",
      "나는 두 손으로 작은 컵을 감싸 쥔다—  \n",
      "차가움이 손바닥을 타고 올라와  \n",
      "마음의 뜨거운 곳을 살짝 식혀준다.\n",
      "\n",
      "바닐라의 하얀 숨,  \n",
      "초콜릿의 깊은 그림자,  \n",
      "딸기의 붉은 웃음이  \n",
      "한 숟갈 안에서 서로를 안아  \n",
      "어린 날의 내 이름을 불러낸다.\n",
      "\n",
      "녹아 흐르는 건 아이스크림만이 아니다.  \n",
      "미처 말하지 못한 미안함,  \n",
      "돌아갈 수 없는 오후,  \n",
      "괜찮은 척하던 서운함이  \n",
      "조용히, 아주 조용히 풀린다.\n",
      "\n",
      "그래서 나는  \n",
      "다 녹기 전에 서둘러 먹으면서도  \n",
      "어쩐지 다 녹아버리길 바란다.  \n",
      "\n",
      "사라지는 것만이  \n",
      "이렇게 다정할 때가 있으니까.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnableLambda  # 병렬 실행 / 함수 Runnable\n",
    "\n",
    "llm = init_chat_model('openai:gpt-5.2')\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "acrostic_poem_prompt = PromptTemplate.from_template(\n",
    "    '당신은 창의적인 n행시 고수입니다. 다음 주제로 n행시를 지어주세요.\\n\\n주제:{topic}'\n",
    ")\n",
    "acrostic_poem_chain = acrostic_poem_prompt | llm | output_parser\n",
    "\n",
    "joke_prompt = PromptTemplate.from_template(\n",
    "    '당신은 너무 웃긴 농담 고수입니다. 다음 주제로 허를 찌르는 농담을 하나 해주세요.\\n\\n주제:{topic}'\n",
    ")\n",
    "joke_chain = joke_prompt | llm | output_parser\n",
    "\n",
    "poem_prompt = PromptTemplate.from_template(\n",
    "    '당신은 위대한 시인입니다. 다음 주제로 감성적인 시를 지어주세요.\\n\\n주제:{topic}'\n",
    ")\n",
    "poem_chain = poem_prompt | llm | output_parser\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    acrostic_poem = acrostic_poem_chain,\n",
    "    joke = joke_chain,\n",
    "    poem = poem_chain\n",
    ")\n",
    "\n",
    "def combine_result(input_dict: dict) -> str:\n",
    "    \"\"\"병렬 결과(n행시/농담/시)를 한 문자열로 합쳐 반환한다.\"\"\"\n",
    "    acrostic_poem = input_dict['acrostic_poem']\n",
    "    joke = input_dict['joke']\n",
    "    poem = input_dict['poem']\n",
    "    return f\"\"\"\n",
    "n행시:\n",
    "{acrostic_poem}\n",
    "\n",
    "농담:\n",
    "{joke}\n",
    "\n",
    "시:\n",
    "{poem}\n",
    "\"\"\"\n",
    "\n",
    "chain = chain | RunnableLambda(combine_result)\n",
    "print(chain.invoke({'topic': '아이스크림'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e9f162",
   "metadata": {},
   "source": [
    "## RunnablePassThought\n",
    "- 사용자의 입력값을 그대로 전달\n",
    "- 입력 dict를 확장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4253da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'텀: 텀텀 뛰는 일상 속  \\n블: 블렌딩된 나만의 향기와  \\n러: 러블리하게 하루를 채워가요!'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough  # 입력을 그대로 통과시키는 Runnable\n",
    "\n",
    "llm = init_chat_model('openai:gpt-4.1-mini')\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    '당신은 창의적인 n행시 고수입니다. 다음 주제로 n행시를 지어주세요.\\n\\n주제:{topic}'\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {'topic': RunnablePassthrough()}  # 입력(문자열)을 그대로 받아 {'topic': 입력}으로 매핑\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "chain.invoke('텀블러')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d811d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'===== 학원 2행시 =====  \\n학 - 학교보다 더 가까운 곳에서  \\n원 - 원하는 꿈을 키워 가네'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough  # 입력을 그대로 통과시키는 Runnable\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "당신은 창의적인 {n}행시 고수입니다. 다음 주제로 {n}행시를 지어주세요.\n",
    "\n",
    "# 주제:\n",
    "{topic}\n",
    "\n",
    "# 출력형식:\n",
    "===== <주제> <n>행시 =====\n",
    "<n행시 작성>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {'topic': RunnablePassthrough()}\n",
    "    | RunnablePassthrough.assign(     # 기존 dict를 확장해서 새 key를 추가\n",
    "        n=lambda x: len(x['topic'])   # topic 길이로 n 계산\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "chain.invoke('학원')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
